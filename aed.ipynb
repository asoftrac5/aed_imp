{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d813b723",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b9b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c328a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d4c5f",
   "metadata": {},
   "source": [
    "# Split dataset\n",
    "## Random Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55c0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Construct the rating matrix based on train_df:\n",
      "[[0. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "Construct the rating matrix based on test_df:\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Testsize = 17678\n",
      "Trainsizse = 80000\n"
     ]
    }
   ],
   "source": [
    "# please do not change this cell\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 10)\n",
    "train_df, test_df\n",
    "\n",
    "# Training Dataset\n",
    "trainsize = 0\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "item_popularity = np.zeros(n_items)\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "    item_popularity[row[2]-1] =  item_popularity[row[2]-1] + 1\n",
    "    trainsize = trainsize + 1\n",
    "#train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "testsize = 0\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    if item_popularity[row[2]-1] > 30:\n",
    "        test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "        testsize = testsize + 1\n",
    "#test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)\n",
    "\n",
    "print(\"Testsize = \" + str(testsize))\n",
    "print(\"Trainsizse = \" + str(trainsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91d27b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b927f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "# you can use this devaluate Utils here, and you can also implement your own MAE and RMSE calculation. \n",
    "\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec09aa5",
   "metadata": {},
   "source": [
    "# Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8c5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# You are required to implement the required solution here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c904079",
   "metadata": {},
   "source": [
    "## User-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df5f0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cdd96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# You are required to implement the required solution here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed3078",
   "metadata": {},
   "source": [
    "### Compute Ajusted Euclidean Distance for Each Pair of Users in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688cee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the maximum value for the recommendation system\n",
    "V_max = np.max(train_ds)\n",
    "\n",
    "# the minimum value for the recommendation system\n",
    "V_min = np.min(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322eb8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.77889168, 0.5527864 , ..., 0.78091098, 0.65358984,\n",
       "        0.68434772],\n",
       "       [0.77889168, 1.        , 0.65358984, ..., 0.61270167, 0.7018576 ,\n",
       "        0.88452995],\n",
       "       [0.5527864 , 0.65358984, 1.        , ..., 0.68377223, 0.6072078 ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.78091098, 0.61270167, 0.68377223, ..., 1.        , 0.8       ,\n",
       "        0.74701779],\n",
       "       [0.65358984, 0.7018576 , 0.6072078 , ..., 0.8       , 1.        ,\n",
       "        0.76466064],\n",
       "       [0.68434772, 0.88452995, 1.        , ..., 0.74701779, 0.76466064,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAMMA = 30\n",
    "EPSILON = 1e-9\n",
    "\n",
    "np_user_adjusted_euclidean_dist = np.zeros((n_users, n_users))\n",
    "\n",
    "for u, user_u_vec in enumerate(train_ds):\n",
    "    for v, user_v_vec in enumerate(train_ds):\n",
    "\n",
    "        # ratings corated by the current pair of users\n",
    "        mask_u = user_u_vec > 0\n",
    "        mask_v = user_v_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_u), np.where(mask_v))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue \n",
    "        \n",
    "        # compute adjusted euclidean distance\n",
    "        \n",
    "        #ru,s - rv,s\n",
    "        user_u_user_v_sub_dif = user_u_vec[corrated_index] - user_v_vec[corrated_index]\n",
    "        \n",
    "        # computes the square of the difference between the ratings of users on the \n",
    "        # co-rated items\n",
    "        user_u_user_v_sub_dif_sq = np.square(user_u_user_v_sub_dif)\n",
    "        \n",
    "        # dist_u_v\n",
    "        dist_u_v = np.sqrt(np.sum(user_u_user_v_sub_dif_sq))   \n",
    "    \n",
    "        # m is the number of members in the set of items co-rated by both users\n",
    "        m = len(corrated_index)\n",
    "            \n",
    "        # V_max - V_min\n",
    "        V_max_V_min_dif = V_max - V_min\n",
    "        \n",
    "        # It computes the square of the difference between the maximum and \n",
    "        # the minimum ratings for the recommendation system\n",
    "        V_max_V_min_dif_sq = np.square(V_max_V_min_dif)\n",
    "\n",
    "        # The product of the number of members in the set of all items co-rated\n",
    "        # by both users and the square of the difference between the V_max and V_min\n",
    "        V_max_V_min_dif_times_m = m * V_max_V_min_dif_sq\n",
    "        \n",
    "        # It gives the dist_max value\n",
    "        dist_max = np.sqrt(V_max_V_min_dif_times_m)\n",
    "\n",
    "        # dist_u_v / dist_max\n",
    "        dist_uv_dist_max_quo = dist_u_v / dist_max\n",
    "        \n",
    "        # similarity\n",
    "        sim = 1 - dist_uv_dist_max_quo\n",
    "\n",
    "        np_user_adjusted_euclidean_dist[u][v] = sim\n",
    "\n",
    "np_user_adjusted_euclidean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab85418",
   "metadata": {},
   "source": [
    "## Predict Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ec907",
   "metadata": {},
   "source": [
    "### Determination of the suitable K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5acd38c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 10, MAE: 0.4024433403050918, RMSE: 0.7313076979922634\n",
      "K: 15, MAE: 0.32653212012389526, RMSE: 0.6624886920529744\n",
      "K: 20, MAE: 0.2729784936234361, RMSE: 0.6041453639780325\n",
      "K: 25, MAE: 0.2384810026293552, RMSE: 0.5623611706205238\n",
      "K: 30, MAE: 0.21304417013397986, RMSE: 0.5301509696579586\n",
      "K: 35, MAE: 0.1990046999561297, RMSE: 0.5075051407373524\n",
      "K: 40, MAE: 0.19339626496696558, RMSE: 0.4998279750307036\n",
      "K: 45, MAE: 0.18830183279516122, RMSE: 0.4933867318482221\n",
      "K: 50, MAE: 0.18051187166897656, RMSE: 0.48185642726737965\n",
      "K: 55, MAE: 0.17860096842839532, RMSE: 0.47882626169927606\n",
      "K: 60, MAE: 0.17567920897521475, RMSE: 0.47464018079039294\n",
      "K: 65, MAE: 0.17544390091186166, RMSE: 0.4747571127671607\n",
      "K: 70, MAE: 0.17428319061100217, RMSE: 0.4761039303805811\n",
      "K: 75, MAE: 0.17450492250161745, RMSE: 0.4763131970745264\n",
      "K: 80, MAE: 0.1740939953958801, RMSE: 0.4753024868701749\n",
      "K: 85, MAE: 0.1726799779869552, RMSE: 0.47264623540045764\n",
      "K: 90, MAE: 0.17175838077800432, RMSE: 0.47137328717520754\n",
      "K: 95, MAE: 0.1713535700910984, RMSE: 0.4687313902086791\n",
      "K: 100, MAE: 0.17179229090440176, RMSE: 0.47003970390675237\n",
      "Best K: 95, Best MAE: 0.1713535700910984, Best RMSE: 0.4687313902086791\n"
     ]
    }
   ],
   "source": [
    "def find_best_k(train_ds, test_ds, np_user_adjusted_euclidean_dist, K_values):\n",
    "    n_users, n_items = test_ds.shape\n",
    "    EPSILON = 1e-9\n",
    "\n",
    "    # Precompute sums and counts for all users to avoid repeated computation\n",
    "    train_ds_sum = np.sum(train_ds, axis=1)\n",
    "    train_ds_count = np.clip(train_ds, 0, 1).sum(axis=1) + EPSILON\n",
    "    \n",
    "    best_k = None\n",
    "    best_mae = float('inf')\n",
    "    best_rmse = float('inf')\n",
    "\n",
    "    for K in K_values:\n",
    "        np_predictions_ead = np.zeros((n_users, n_items))\n",
    "        \n",
    "        for (i, j), rating in np.ndenumerate(test_ds):\n",
    "            if rating > 0:\n",
    "                # Find top-k most similar users to the current user, excluding itself\n",
    "                sim_user_ids = np.argsort(np_user_adjusted_euclidean_dist[i])[-(K + 1):-1]\n",
    "\n",
    "                # The AED values of similar users\n",
    "                sim_val = np_user_adjusted_euclidean_dist[i][sim_user_ids]\n",
    "\n",
    "                # The similar users' ratings\n",
    "                sim_users = test_ds[sim_user_ids]\n",
    "\n",
    "                # Select the similar users who rated item j\n",
    "                mask_rated_j = sim_users[:, j] > 0\n",
    "\n",
    "                # If there is no similar users who have rated item s\n",
    "                if not mask_rated_j.any():\n",
    "                    # It computes the mean value of ratings of current user on the rated items\n",
    "                    user_mean_rating = train_ds_sum[i] / train_ds_count[i]\n",
    "                    np_predictions_ead[i][j] = user_mean_rating\n",
    "                    np_predictions_ead[i][j] = np.clip(np_predictions_ead[i][j], 0, 5)\n",
    "\n",
    "                # If there exist similar users who have rated item s\n",
    "                else:\n",
    "                    # Initialize set and lists for users with dist(c, c') = 0\n",
    "                    sim_user_mask = sim_users[mask_rated_j]\n",
    "                    sim_val_mask = sim_val[mask_rated_j]\n",
    "                    C_cap_0 = np.where(sim_val_mask == 1)[0]\n",
    "\n",
    "                    # If the C_cap_0 has no elements\n",
    "                    if C_cap_0.size == 0:\n",
    "                        # Lets find the absolute value of each current, similar users pairs\n",
    "                        abs_sim_val = np.abs(sim_val_mask)\n",
    "        #                 print(f\"sim_val_mask: {sim_val_mask}\")\n",
    "                        # The sum of the absolute similarity values of each current, similar users pairs\n",
    "                        abs_sim_val_sum = np.sum(abs_sim_val)\n",
    "\n",
    "                        # Lets compute the value of k\n",
    "                        k = 1 / abs_sim_val_sum\n",
    "\n",
    "                        # The product of similarity and the rating of the similar_user on item j\n",
    "                        sv_r_cprime_s_prod = sim_val_mask * sim_user_mask[:, j]\n",
    "\n",
    "                        # The sum of product of similarity and rating of the similar_user on item j\n",
    "                        sv_r_cprime_s_prod_sum = np.sum(sv_r_cprime_s_prod)\n",
    "\n",
    "                        # Predictions using aed\n",
    "                        np_predictions_ead[i][j] = k * sv_r_cprime_s_prod_sum\n",
    "                        np_predictions_ead[i][j] = np.clip(np_predictions_ead[i][j], 0, 5)\n",
    "\n",
    "                    else:\n",
    "                        # Lets compute the number of co-rated items for each similar user\n",
    "                        # Which has the dist(c, c_cap) = 0\n",
    "                        m_ccap = np.array([\n",
    "                            np.sum(np.logical_and(su > 0, test_ds[i] > 0))\n",
    "                            for su in sim_user_mask[C_cap_0]\n",
    "                        ])\n",
    "                        \n",
    "                        # Calculates the rating of similar user on item j\n",
    "                        r_ccap_s = sim_user_mask[C_cap_0, j]\n",
    "\n",
    "                        # Calculates the sum of the ratings of similar users on item j\n",
    "                        m_ccap_sum = np.sum(m_ccap)\n",
    "\n",
    "                        # Computes the value for K note\n",
    "                        k_0 = 1 / m_ccap_sum\n",
    "\n",
    "                        # Computes the product of number of co-rated itmes for user c and ccap and \n",
    "                        # the ratings of the corresponding ccap\n",
    "                        m_ccap_ccap_s_prod = m_ccap * r_ccap_s\n",
    "\n",
    "                        # The total sum of the product of m_ccap and r_ccap_s\n",
    "                        m_ccap_ccap_s_prod_sum = np.sum(m_ccap_ccap_s_prod)\n",
    "\n",
    "                        # the predicted rating\n",
    "                        np_predictions_ead[i][j] = k_0 * m_ccap_ccap_s_prod_sum\n",
    "                        np_predictions_ead[i][j] = np.clip(np_predictions_ead[i][j], 0, 5)\n",
    "        \n",
    "        mae, rmse = evaluate(np_predictions_ead, test_ds)\n",
    "        print(f\"K: {K}, MAE: {mae}, RMSE: {rmse}\")\n",
    "\n",
    "        if mae < best_mae and rmse < best_rmse:\n",
    "            best_mae = mae\n",
    "            best_rmse = rmse\n",
    "            best_k = K\n",
    "\n",
    "    return best_k, best_mae, best_rmse\n",
    "\n",
    "# Example usage\n",
    "K_values = range(10, 101, 5)  # Try K values from 10 to 50 in steps of 10\n",
    "best_k, best_mae, best_rmse = find_best_k(train_ds, test_ds, np_user_adjusted_euclidean_dist, K_values)\n",
    "print(f\"Best K: {best_k}, Best MAE: {best_mae}, Best RMSE: {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41955030",
   "metadata": {},
   "source": [
    "### Prediction with Suitable K Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba72b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_predictions_ead = np.zeros((n_users, n_items))\n",
    "\n",
    "K = 95\n",
    "EPSILON = 1e-9\n",
    "\n",
    "# Precompute sums and counts for all users to avoid repeated computation\n",
    "train_ds_sum = np.sum(train_ds, axis=1)\n",
    "train_ds_count = np.clip(train_ds, 0, 1).sum(axis=1) + EPSILON\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds):\n",
    "    if rating > 0:\n",
    "        # Find top-k most similar users to the current user, excluding itself\n",
    "        sim_user_ids = np.argsort(np_user_adjusted_euclidean_dist[i])[-(K + 1):-1]\n",
    "        \n",
    "        # The AED values of similar users\n",
    "        sim_val = np_user_adjusted_euclidean_dist[i][sim_user_ids]\n",
    "        \n",
    "        # The similar users' ratings\n",
    "        sim_users = test_ds[sim_user_ids]\n",
    "        \n",
    "        # Select the similar users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # If there is no similar users who have rated item s\n",
    "        if not mask_rated_j.any():\n",
    "            # It computes the mean value of ratings of current user on the rated items\n",
    "            user_mean_rating = train_ds_sum[i] / train_ds_count[i]\n",
    "            np_predictions_ead[i][j] = user_mean_rating\n",
    "            np_predictions_ead[i][j] = np.clip(np_predictions_ead[i][j], 0, 5)\n",
    "        \n",
    "        # If there exist similar users who have rated item s\n",
    "        else:\n",
    "            # Initialize set and lists for users with dist(c, c') = 0\n",
    "            sim_user_mask = sim_users[mask_rated_j]\n",
    "            sim_val_mask = sim_val[mask_rated_j]\n",
    "            C_cap_0 = np.where(sim_val_mask == 1)[0]\n",
    "            \n",
    "            # If the C_cap_0 has no elements\n",
    "            if C_cap_0.size == 0:\n",
    "                # Lets find the absolute value of each current, similar users pairs\n",
    "                abs_sim_val = np.abs(sim_val_mask)\n",
    "#                 print(f\"sim_val_mask: {sim_val_mask}\")\n",
    "                # The sum of the absolute similarity values of each current, similar users pairs\n",
    "                abs_sim_val_sum = np.sum(abs_sim_val)\n",
    "\n",
    "                # Lets compute the value of k\n",
    "                k = 1 / abs_sim_val_sum\n",
    "                \n",
    "                # The product of similarity and the rating of the similar_user on item j\n",
    "                sv_r_cprime_s_prod = sim_val_mask * sim_user_mask[:, j]\n",
    "\n",
    "                # The sum of product of similarity and rating of the similar_user on item j\n",
    "                sv_r_cprime_s_prod_sum = np.sum(sv_r_cprime_s_prod)\n",
    "                \n",
    "                # Predictions using aed\n",
    "                np_predictions_ead[i][j] = k * sv_r_cprime_s_prod_sum\n",
    "                np_predictions_ead[i][j] = np.clip(np_predictions_ead[i][j], 0, 5)\n",
    "\n",
    "            else:\n",
    "                # Lets compute the number of co-rated items for each similar user\n",
    "                # Which has the dist(c, c_cap) = 0\n",
    "                m_ccap = np.array([\n",
    "                    np.sum(np.logical_and(su > 0, test_ds[i] > 0))\n",
    "                    for su in sim_user_mask[C_cap_0]\n",
    "                ])\n",
    "\n",
    "                # Calculates the rating of similar user on item j\n",
    "                r_ccap_s = sim_user_mask[C_cap_0, j]\n",
    "                \n",
    "                # Calculates the sum of the ratings of similar users on item j\n",
    "                m_ccap_sum = np.sum(m_ccap)\n",
    "                \n",
    "                # Computes the value for K note\n",
    "                k_0 = 1 / m_ccap_sum\n",
    "\n",
    "                # Computes the product of number of co-rated itmes for user c and ccap and \n",
    "                # the ratings of the corresponding ccap\n",
    "                m_ccap_ccap_s_prod = m_ccap * r_ccap_s\n",
    "                \n",
    "                # The total sum of the product of m_ccap and r_ccap_s\n",
    "                m_ccap_ccap_s_prod_sum = np.sum(m_ccap_ccap_s_prod)\n",
    "\n",
    "                # the predicted rating\n",
    "                np_predictions_ead[i][j] = k_0 * m_ccap_ccap_s_prod_sum\n",
    "                np_predictions_ead[i][j] = np.clip(np_predictions_ead[i][j], 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512281d6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dc6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_score = evaluate(test_ds, np_predictions_ead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2f81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "# The Following MAE and RMSE is for Adjusted Euclidean Distance\n",
    "# The value of K is set to 10\n",
    "\n",
    "MAE = evaluation_score[0] # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "RMSE = evaluation_score[1] # 0 is an intial value, you need to update this with the actual perofrmance of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e89b6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.1713535700910984, RMSE: 0.4687313902086791\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21185a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have tried to implement as per the report research paper\n",
    "# The implementation of equations are in the exact and \n",
    "# As mentioned concept in the research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29727e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks and Regards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8b9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
